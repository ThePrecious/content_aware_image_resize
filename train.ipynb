{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import logging \n",
    "log = logging.getLogger(\"basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = glob.glob(os.path.join('/data/train_data/balanced_image/', '*.jpg'))\n",
    "train_mask = glob.glob(os.path.join('/data/train_data/balanced_mask/', '*.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = glob.glob(os.path.join('/data/test_data/balanced_image/', '*.jpg'))\n",
    "test_mask = glob.glob(os.path.join('/data/test_data/balanced_mask/', '*.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 496, 384\n",
    "        \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, train=True):   # initial logic happens like transform\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transforms = transforms.ToTensor()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = Image.open(self.image_paths[index]).convert('RGB').resize((width, height)) \n",
    "        image = np.array(image)\n",
    "        \n",
    "        mask = Image.open(self.mask_paths[index]).convert('RGB').resize((width, height))\n",
    "        mask = np.array(mask)\n",
    "        return self.transforms(image), self.transforms(mask)\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_dataset = CustomDataset(train_image[:], train_mask[:], train=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the loader\n",
    "#for _,(images, masks) in enumerate(train_loader):\n",
    "    #print (images.shape)\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_image[:], test_mask[:], train=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        act_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_trans_block(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim,out_dim, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        act_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def maxpool():\n",
    "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    return pool\n",
    "\n",
    "\n",
    "def conv_block_2(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        conv_block(in_dim,out_dim,act_fn),\n",
    "        nn.Conv2d(out_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "    )\n",
    "    return model    \n",
    "\n",
    "\n",
    "def conv_block_3(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        conv_block(in_dim,out_dim,act_fn),\n",
    "        conv_block(out_dim,out_dim,act_fn),\n",
    "        nn.Conv2d(out_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "class UnetGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self,in_dim,out_dim,num_filter):\n",
    "        super(UnetGenerator,self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_filter = num_filter\n",
    "        act_fn = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.down_1 = conv_block_2(self.in_dim,self.num_filter,act_fn)\n",
    "        self.pool_1 = maxpool()\n",
    "        self.down_2 = conv_block_2(self.num_filter*1,self.num_filter*2,act_fn)\n",
    "        self.pool_2 = maxpool()\n",
    "        self.down_3 = conv_block_2(self.num_filter*2,self.num_filter*4,act_fn)\n",
    "        self.pool_3 = maxpool()\n",
    "        self.down_4 = conv_block_2(self.num_filter*4,self.num_filter*8,act_fn)\n",
    "        self.pool_4 = maxpool()\n",
    "\n",
    "        self.bridge = conv_block_2(self.num_filter*8,self.num_filter*16,act_fn)\n",
    "\n",
    "        self.trans_1 = conv_trans_block(self.num_filter*16,self.num_filter*8,act_fn)\n",
    "        self.up_1 = conv_block_2(self.num_filter*16,self.num_filter*8,act_fn)\n",
    "        self.trans_2 = conv_trans_block(self.num_filter*8,self.num_filter*4,act_fn)\n",
    "        self.up_2 = conv_block_2(self.num_filter*8,self.num_filter*4,act_fn)\n",
    "        self.trans_3 = conv_trans_block(self.num_filter*4,self.num_filter*2,act_fn)\n",
    "        self.up_3 = conv_block_2(self.num_filter*4,self.num_filter*2,act_fn)\n",
    "        self.trans_4 = conv_trans_block(self.num_filter*2,self.num_filter*1,act_fn)\n",
    "        self.up_4 = conv_block_2(self.num_filter*2,self.num_filter*1,act_fn)\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(self.num_filter,self.out_dim,3,1,1),\n",
    "            nn.Sigmoid(), \n",
    "        )\n",
    "\n",
    "    def forward(self,input):\n",
    "        down_1 = self.down_1(input)\n",
    "        pool_1 = self.pool_1(down_1)\n",
    "        down_2 = self.down_2(pool_1)\n",
    "        pool_2 = self.pool_2(down_2)\n",
    "        down_3 = self.down_3(pool_2)\n",
    "        pool_3 = self.pool_3(down_3)\n",
    "        down_4 = self.down_4(pool_3)\n",
    "        pool_4 = self.pool_4(down_4)\n",
    "\n",
    "        bridge = self.bridge(pool_4)\n",
    "\n",
    "        trans_1 = self.trans_1(bridge)\n",
    "        concat_1 = torch.cat([trans_1,down_4],dim=1)\n",
    "        up_1 = self.up_1(concat_1)\n",
    "        trans_2 = self.trans_2(up_1)\n",
    "        \n",
    "        t2_shape = trans_2.shape\n",
    "        concat_2 = torch.cat([trans_2, down_3[:,:,:,:t2_shape[-1]]],dim=1)\n",
    "        up_2 = self.up_2(concat_2)\n",
    "        trans_3 = self.trans_3(up_2)\n",
    "        \n",
    "        t3_shape = trans_3.shape\n",
    "        \n",
    "        concat_3 = torch.cat([trans_3, down_2[:,:,:,:t3_shape[-1]]],dim=1)\n",
    "        up_3 = self.up_3(concat_3)\n",
    "        trans_4 = self.trans_4(up_3)\n",
    "        \n",
    "        t4_shape = trans_4.shape\n",
    "\n",
    "        concat_4 = torch.cat([trans_4, down_1[:,:,:,:t4_shape[-1]]],dim=1)\n",
    "        up_4 = self.up_4(concat_4)\n",
    "\n",
    "        out = self.out(up_4)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetGenerator(3,3,64)\n",
    "model = model.to(device, dtype=torch.float)\n",
    "lr = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different loss functions - MSE, Weighted_MSE\n",
    "# Change cell from markdown to code for the loss function cell that you want to try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted MSE\n",
    "HEIGHT, WIDTH = height, width\n",
    "WEIGHTS = np.ones((3, height, width))\n",
    "\n",
    "#option1:  pixels 0 to 124, 372 to 496 weigh them 0.25\n",
    "#WEIGHTS[:, :,  :int(width/4)] *= 0.25 \n",
    "#WEIGHTS[:, :,  -2 *int(width/4):] *= 0.25 \n",
    "\n",
    "#option2:  pixels 0 to 124 0.2, 372 to 496 weigh them 0.1\n",
    "WEIGHTS[:, :,  0:124] *= 0.2 \n",
    "WEIGHTS[:, :,  372:] *= 0.1 \n",
    "\n",
    "def weighted_mse_loss(inp, target, weights=None):\n",
    "    if not weights:\n",
    "        weights = torch.Tensor(WEIGHTS)\n",
    "    \n",
    "    # add weighted zones.    \n",
    "    weights = Variable(weights).to(device)\n",
    "    out = (inp - target)**2\n",
    "    out = out * weights.expand_as(out)\n",
    "    return torch.mean(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE \n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_f1score(model, test_loader):\n",
    "    model.eval()\n",
    "    f1_list = []\n",
    "    for _,(images, masks) in enumerate(test_loader):\n",
    "        images = Variable(images).to(device)\n",
    "        predicted_labels = model.forward(images)\n",
    "        flat_pred = predicted_labels.detach().cpu().numpy().flatten()\n",
    "        flat_label = masks.detach().cpu().numpy().flatten()\n",
    "        flat_pred[flat_pred >= 0.5] = 1\n",
    "        flat_pred[flat_pred <0.5] = 0\n",
    "        f1 = f1_score(flat_pred.astype('int32'), flat_label.astype('int32'), average=\"micro\")\n",
    "        f1_list.append(f1)\n",
    "    return f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 999\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    for _, (images, masks) in enumerate(train_loader):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = Variable(images).to(device)\n",
    "        y_ = Variable(masks).to(device)\n",
    "        y = model.forward(x)\n",
    "        \n",
    "        loss = loss_func(y, y_)  #weighted_mse_loss(y, y_) #.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if _ % 10 == 0:\n",
    "            print(\"Epoch: %s Batch ID: %s Loss: %s\" % (i, _, loss.detach().cpu().numpy()))\n",
    "\n",
    "    ## Test after every epoch\n",
    "    \n",
    "    numerical_loss = loss.detach().cpu().numpy().tolist()\n",
    "    if  numerical_loss < min_loss:\n",
    "        min_loss = numerical_loss\n",
    "        torch.save(model, 'best_model.pth')\n",
    "        \n",
    "      \n",
    "                \n",
    "    # Evaluate Predictions using F1 score\n",
    "    f1_list = evaluate_f1score(model, test_loader)\n",
    "    print (\"Evaluation F1\", i, np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Formatted Results\n",
    "\n",
    "out_images = []\n",
    "out_masks = []\n",
    "orig_masks = []\n",
    "def mse(A, B, ax=0):\n",
    "    return np.square(A.flatten() - B.flatten()).mean(axis=ax)\n",
    "\n",
    "for _,(images, masks) in enumerate(test_loader):\n",
    "    images = Variable(images).to(device)\n",
    "    predicted_labels = model.forward(images)\n",
    "    flat_pred = predicted_labels.detach().cpu().numpy().flatten()\n",
    "    flat_label = masks.detach().cpu().numpy().flatten()\n",
    "    flat_pred[flat_pred >= 0.5] = 1\n",
    "    flat_pred[flat_pred <0.5] = 0\n",
    "    f1 = f1_score(flat_pred.astype('int32'), flat_label.astype('int32'), average=\"micro\")\n",
    "    f1_weighted = f1_score(flat_pred.astype('int32'), flat_label.astype('int32'), average=\"weighted\")\n",
    "    batch_mse = np.mean(mse(flat_pred, flat_label))\n",
    "    print (\"Batch: %s, F1.micro: %.4f, F1.weighted: %.4f, MSE: %s\" % (_, f1, f1_weighted, batch_mse))\n",
    "    for idx in range(images.shape[0]):\n",
    "        pred_mask_img = predicted_labels.detach().cpu().numpy()[idx]\n",
    "        o_img = images.detach().cpu().numpy()[idx]\n",
    "        out_images.append(o_img)\n",
    "        out_masks.append(pred_mask_img)\n",
    "        orig_masks.append(masks.cpu().numpy()[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(im):\n",
    "    ''' swap axes '''\n",
    "    im = np.swapaxes(im, 0, 2)\n",
    "    im = np.swapaxes(im, 0, 1)\n",
    "    return im \n",
    "\n",
    "def show_image_and_mask(pred_mask_img, o_img, o_mask, idx):\n",
    "    seam_pred_mask = get_img(pred_mask_img)\n",
    "    seam_pred_mask = np.mean(seam_pred_mask,axis=2)    \n",
    "    orig_img = get_img(o_img)\n",
    "    col_sum = np.sum(seam_pred_mask, axis=0)\n",
    "    idx_to_keep = col_sum.argsort()[:400]\n",
    "    idx_to_keep.sort()\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(14, 8), sharex=False, sharey=True)\n",
    "    ax[0].imshow(orig_img)\n",
    "    ax[0].set_title(\"original image\")\n",
    "    \n",
    "    ax[1].imshow(get_img(o_mask))\n",
    "    ax[1].set_title(\"original mask\")\n",
    "\n",
    "    ax[2].imshow(seam_pred_mask, cmap='gray')\n",
    "    ax[2].set_title(\"predicted mask\")\n",
    "    \n",
    "    ax[3].imshow(orig_img[:, idx_to_keep])\n",
    "    ax[3].set_title(\"u-net resized image\")\n",
    "    \n",
    "    fig.savefig('best_model_results/%s.jpg' %idx)\n",
    "    \n",
    "    print (orig_img[:, idx_to_keep].shape, orig_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(out_masks)):\n",
    "    show_image_and_mask(out_masks[idx], out_images[idx], orig_masks[idx], idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
